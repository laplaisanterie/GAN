{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9. Pix2Pix.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laplaisanterie/GAN/blob/master/4.%20Pix2Pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRHSHGLVjTvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teOVRLWhji8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "folder = \"colab/\"\n",
        "project_dir = \"pix2pix\"\n",
        "\n",
        "base_path = Path(\"/content/gdrive/My Drive/\")\n",
        "project_path = base_path / folder / project_dir\n",
        "os.chdir(project_path)\n",
        "for x in list(project_path.glob(\"*\")):\n",
        "    if x.is_dir():\n",
        "        dir_name = str(x.relative_to(project_path))\n",
        "        os.rename(dir_name, dir_name.split(\" \", 1)[0])\n",
        "print(f\"현재 디렉토리 위치: {os.getcwd()}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqmy_FVH6w3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from torch.autograd import Variable\n",
        "from itertools import chain\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print('pytorch version: {}'.format(torch.__version__))\n",
        "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIIowgv48QWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_variable(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg57sVDa8SRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwptt6z38TkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GAN_Loss(input, target, criterion):\n",
        "    if target == True:\n",
        "        tmp_tensor = torch.FloatTensor(input.size()).fill_(1.0)\n",
        "        labels = Variable(tmp_tensor, requires_grad=False)\n",
        "    else:\n",
        "        tmp_tensor = torch.FloatTensor(input.size()).fill_(0.0)\n",
        "        labels = Variable(tmp_tensor, requires_grad=False)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        labels = labels.cuda()\n",
        "\n",
        "    return criterion(input, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKj-0WkA60zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "which_direction = 'AtoB'\n",
        "\n",
        "num_epochs = 100\n",
        "batchSize = 1\n",
        "lr = 0.0002\n",
        "beta1 = 0.5 \n",
        "beta2 = 0.999\n",
        "lambda_A = 100.0\n",
        "\n",
        "sample_path = './results'\n",
        "log_step = 10\n",
        "sample_step = 100\n",
        "num_workers = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxl6uWkq_nUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageFolder(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.transformP = transforms.Compose([\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                                                  (0.5, 0.5, 0.5))])\n",
        "        \n",
        "        self.image_len = None\n",
        "\n",
        "        self.dir_base = './datasets'\n",
        "        \n",
        "        self.rootA = os.path.join(self.dir_base, 'pikachu_black')\n",
        "        self.rootB = os.path.join(self.dir_base, 'pikachu_resized2')\n",
        "        self.image_paths_A = list(map(lambda x: os.path.join(self.rootA, x), os.listdir(self.rootA)))\n",
        "        self.image_paths_B = list(map(lambda x: os.path.join(self.rootB, x), os.listdir(self.rootB)))\n",
        "        self.image_paths_A.sort()\n",
        "        self.image_paths_B.sort()\n",
        "        self.image_len = min(len(self.image_paths_A), len(self.image_paths_B))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        A_path = self.image_paths_A[index]\n",
        "        B_path = self.image_paths_B[index]\n",
        "        A = Image.open(A_path).convert('RGB')\n",
        "        B = Image.open(B_path).convert('RGB')\n",
        "\n",
        "        A = self.transformP(A)\n",
        "        B = self.transformP(B)\n",
        "\n",
        "        return {'A': A, 'B': B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.image_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcsJjfo69UR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = ImageFolder()\n",
        "data_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batchSize,\n",
        "                          shuffle=True,\n",
        "                          num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cYOjUQXBFG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if not os.path.exists(sample_path):\n",
        "    os.makedirs(sample_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtC4uZr-9WOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        bn = None\n",
        "        if batch_size == 1:\n",
        "            bn = False # Instance Normalization\n",
        "        else:\n",
        "            bn = True # Batch Normalization\n",
        "\n",
        "        # [3x256x256] -> [64x128x128]\n",
        "        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n",
        "\n",
        "        # -> [128x64x64]\n",
        "        conv2 = [nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            conv2 += [nn.BatchNorm2d(128)]\n",
        "        else:\n",
        "            conv2 += [nn.InstanceNorm2d(128)]\n",
        "        self.conv2 = nn.Sequential(*conv2)\n",
        "\n",
        "        # -> [256x32x32]\n",
        "        conv3 = [nn.LeakyReLU(0.2, inplace=True),\n",
        "                 nn.Conv2d(128, 256, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            conv3 += [nn.BatchNorm2d(256)]\n",
        "        else:\n",
        "            conv3 += [nn.InstanceNorm2d(256)]\n",
        "        self.conv3 = nn.Sequential(*conv3)\n",
        "\n",
        "        # -> [512x16x16]\n",
        "        conv4 = [nn.LeakyReLU(0.2, inplace=True),\n",
        "                 nn.Conv2d(256, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            conv4 += [nn.BatchNorm2d(512)]\n",
        "        else:\n",
        "            conv4 += [nn.InstanceNorm2d(512)]\n",
        "        self.conv4 = nn.Sequential(*conv4)\n",
        "\n",
        "        # -> [512x8x8]\n",
        "        conv5 = [nn.LeakyReLU(0.2, inplace=True),\n",
        "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            conv5 += [nn.BatchNorm2d(512)]\n",
        "        else:\n",
        "            conv5 += [nn.InstanceNorm2d(512)]\n",
        "        self.conv5 = nn.Sequential(*conv5)\n",
        "\n",
        "        # -> [512x4x4]\n",
        "        conv6 = [nn.LeakyReLU(0.2, inplace=True),\n",
        "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            conv6 += [nn.BatchNorm2d(512)]\n",
        "        else:\n",
        "            conv6 += [nn.InstanceNorm2d(512)]\n",
        "        self.conv6 = nn.Sequential(*conv6)\n",
        "\n",
        "        # -> [512x2x2]\n",
        "        conv7 = [nn.LeakyReLU(0.2, inplace=True),\n",
        "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            conv7 += [nn.BatchNorm2d(512)]\n",
        "        else:\n",
        "            conv7 += [nn.InstanceNorm2d(512)]\n",
        "        self.conv7 = nn.Sequential(*conv7)\n",
        "\n",
        "        # -> [512x1x1]\n",
        "        conv8 = [nn.LeakyReLU(0.2, inplace=True),\n",
        "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            conv8 += [nn.BatchNorm2d(512)]\n",
        "        else:\n",
        "            conv8 += [nn.InstanceNorm2d(512)]\n",
        "        self.conv8 = nn.Sequential(*conv8)\n",
        "\n",
        "        # -> [512x2x2]\n",
        "        deconv8 = [nn.ReLU(),\n",
        "                   nn.ConvTranspose2d(512, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            deconv8 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
        "        else:\n",
        "            deconv8 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
        "        self.deconv8 = nn.Sequential(*deconv8)\n",
        "\n",
        "        # [(512+512)x2x2] -> [512x4x4]\n",
        "        deconv7 = [nn.ReLU(),\n",
        "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            deconv7 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
        "        else:\n",
        "            deconv7 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
        "        self.deconv7 = nn.Sequential(*deconv7)\n",
        "\n",
        "        # [(512+512)x4x4] -> [512x8x8]\n",
        "        deconv6 = [nn.ReLU(),\n",
        "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            deconv6 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
        "        else:\n",
        "            deconv6 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
        "        self.deconv6 = nn.Sequential(*deconv6)\n",
        "\n",
        "        # [(512+512)x8x8] -> [512x16x16]\n",
        "        deconv5 = [nn.ReLU(),\n",
        "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            deconv5 += [nn.BatchNorm2d(512)]\n",
        "        else:\n",
        "            deconv5 += [nn.InstanceNorm2d(512)]\n",
        "        self.deconv5 = nn.Sequential(*deconv5)\n",
        "\n",
        "        # [(512+512)x16x16] -> [256x32x32]\n",
        "        deconv4 = [nn.ReLU(),\n",
        "                   nn.ConvTranspose2d(512 * 2, 256, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            deconv4 += [nn.BatchNorm2d(256)]\n",
        "        else:\n",
        "            deconv4 += [nn.InstanceNorm2d(256)]\n",
        "        self.deconv4 = nn.Sequential(*deconv4)\n",
        "\n",
        "        # [(256+256)x32x32] -> [128x64x64]\n",
        "        deconv3 = [nn.ReLU(),\n",
        "                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            deconv3 += [nn.BatchNorm2d(128)]\n",
        "        else:\n",
        "            deconv3 += [nn.InstanceNorm2d(128)]\n",
        "        self.deconv3 = nn.Sequential(*deconv3)\n",
        "\n",
        "        # [(128+128)x64x64] -> [64x128x128]\n",
        "        deconv2 = [nn.ReLU(),\n",
        "                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            deconv2 += [nn.BatchNorm2d(64)]\n",
        "        else:\n",
        "            deconv2 += [nn.InstanceNorm2d(64)]\n",
        "        self.deconv2 = nn.Sequential(*deconv2)\n",
        "\n",
        "        # [(64+64)x128x128] -> [3x256x256]\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        c1 = self.conv1(x)\n",
        "        c2 = self.conv2(c1)\n",
        "        c3 = self.conv3(c2)\n",
        "        c4 = self.conv4(c3)\n",
        "        c5 = self.conv5(c4)\n",
        "        c6 = self.conv6(c5)\n",
        "        c7 = self.conv7(c6)\n",
        "        c8 = self.conv8(c7)\n",
        "\n",
        "        d7 = self.deconv8(c8)\n",
        "        d7 = torch.cat((c7, d7), dim=1)\n",
        "        d6 = self.deconv7(d7)\n",
        "        d6 = torch.cat((c6, d6), dim=1)\n",
        "        d5 = self.deconv6(d6)\n",
        "        d5 = torch.cat((c5, d5), dim=1)\n",
        "        d4 = self.deconv5(d5)\n",
        "        d4 = torch.cat((c4, d4), dim=1)\n",
        "        d3 = self.deconv4(d4)\n",
        "        d3 = torch.cat((c3, d3), dim=1)\n",
        "        d2 = self.deconv3(d3)\n",
        "        d2 = torch.cat((c2, d2), dim=1)\n",
        "        d1 = self.deconv2(d2)\n",
        "        d1 = torch.cat((c1, d1), dim=1)\n",
        "        out = self.deconv1(d1)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        bn = None\n",
        "        if batch_size == 1:\n",
        "            bn = False  # Instance Normalization\n",
        "        else:\n",
        "            bn = True  # Batch Normalization\n",
        "\n",
        "        # [(3+3)x256x256] -> [64x128x128] -> [128x64x64]\n",
        "        main = [nn.Conv2d(3*2, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            main += [nn.BatchNorm2d(128)]\n",
        "        else:\n",
        "            main += [nn.InstanceNorm2d(128)]\n",
        "\n",
        "        # -> [256x32x32]\n",
        "        main += [nn.LeakyReLU(0.2, inplace=True),\n",
        "                  nn.Conv2d(128, 256, 4, 2, 1)]\n",
        "        if bn == True:\n",
        "            main += [nn.BatchNorm2d(256)]\n",
        "        else:\n",
        "            main += [nn.InstanceNorm2d(256)]\n",
        "\n",
        "        # -> [512x31x31] (Fully Convolutional)\n",
        "        main += [nn.LeakyReLU(0.2, inplace=True),\n",
        "                  nn.Conv2d(256, 512, 4, 1, 1)]\n",
        "        if bn == True:\n",
        "            main += [nn.BatchNorm2d(512)]\n",
        "        else:\n",
        "            main += [nn.InstanceNorm2d(512)]\n",
        "\n",
        "        # -> [1x30x30] (Fully Convolutional, PatchGAN)\n",
        "        main += [nn.LeakyReLU(0.2, inplace=True),\n",
        "                  nn.Conv2d(512, 1, 4, 1, 1),\n",
        "                  nn.Sigmoid()]\n",
        "\n",
        "        self.main = nn.Sequential(*main)\n",
        "\n",
        "    def forward(self, x1, x2): # One for Real, One for Fake\n",
        "        out = torch.cat((x1, x2), dim=1)\n",
        "        return self.main(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBmDNzoKA0Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Generator(batchSize)\n",
        "discriminator = Discriminator(batchSize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB2Ae-BYBQkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterionGAN = nn.BCELoss()\n",
        "criterionL1 = nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oydZ7V_CBS7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr, [beta1, beta2])\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr, [beta1, beta2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFDqlmnoBWGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    generator = generator.cuda()\n",
        "    discriminator = discriminator.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Fi9LhbBdLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_step = len(data_loader) # For Print Log\n",
        "for epoch in range(num_epochs):\n",
        "    for i, sample in enumerate(data_loader):\n",
        "\n",
        "        AtoB = which_direction == 'AtoB'\n",
        "        input_A = sample['A' if AtoB else 'B']\n",
        "        input_B = sample['B' if AtoB else 'A']\n",
        "\n",
        "        # ===================== Train D =====================#\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        real_A = to_variable(input_A)\n",
        "        fake_B = generator(real_A)\n",
        "        real_B = to_variable(input_B)\n",
        "\n",
        "        # d_optimizer.zero_grad()\n",
        "\n",
        "        pred_fake = discriminator(real_A, fake_B)\n",
        "        loss_D_fake = GAN_Loss(pred_fake, False, criterionGAN)\n",
        "\n",
        "        pred_real = discriminator(real_A, real_B)\n",
        "        loss_D_real = GAN_Loss(pred_real, True, criterionGAN)\n",
        "\n",
        "        # Combined loss\n",
        "        \n",
        "        loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
        "        loss_D.backward(retain_graph=True)\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # ===================== Train G =====================#\n",
        "        generator.zero_grad()\n",
        "\n",
        "        pred_fake = discriminator(real_A, fake_B)\n",
        "        loss_G_GAN = GAN_Loss(pred_fake, True, criterionGAN)\n",
        "\n",
        "        loss_G_L1 = criterionL1(fake_B, real_B)\n",
        "\n",
        "        loss_G = loss_G_GAN + loss_G_L1 * lambda_A\n",
        "        loss_G.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # print the log info\n",
        "        if (i + 1) % log_step == 0:\n",
        "            print('Epoch [%d/%d], BatchStep[%d/%d], D_Real_loss: %.4f, D_Fake_loss: %.4f, G_loss: %.4f, G_L1_loss: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i + 1, total_step, loss_D_real.item(), loss_D_fake.item(), loss_G_GAN.item(), loss_G_L1.item()))\n",
        "\n",
        "        # save the sampled images\n",
        "        if (i + 1) % sample_step == 0:\n",
        "            res = torch.cat((torch.cat((real_A, fake_B), dim=3), real_B), dim=3)\n",
        "            torchvision.utils.save_image(denorm(res.data), os.path.join(sample_path, 'Generated-%d-%d.png' % (epoch + 1, i + 1)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go0b4-l6HiST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_base = './datasets'\n",
        "rootA = os.path.join(dir_base, 'pikachu_draw')\n",
        "image_paths_A = list(map(lambda x: os.path.join(rootA, x), os.listdir(rootA)))\n",
        "A_path = image_paths_A[0]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                                      (0.5, 0.5, 0.5))])      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JgL0iVeYyYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = Image.open(A_path).convert('RGB')\n",
        "A = transform(A)\n",
        "real_A= to_variable(A)\n",
        "real_A = real_A.unsqueeze(0)\n",
        "fake_B= generator(real_A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_815p6UWXKHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = torch.cat((torch.cat((real_A, fake_B), dim=3), real_A), dim=3)\n",
        "torchvision.utils.save_image(denorm(res.data), os.path.join(sample_path, 'Generated_draw.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}